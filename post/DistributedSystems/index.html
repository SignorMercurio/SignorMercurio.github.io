<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>星罗棋布：《分布式系统与安全》课程笔记 - Lab on Mercury</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Lab on Mercury"><meta name="msapplication-TileImage" content="/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Lab on Mercury"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="《分布式系统与安全》这门课，说不定会成为我从本科到硕士期间最有价值的课。"><meta property="og:type" content="blog"><meta property="og:title" content="星罗棋布：《分布式系统与安全》课程笔记"><meta property="og:url" content="https://signormercurio.me/post/DistributedSystems/"><meta property="og:site_name" content="Lab on Mercury"><meta property="og:description" content="《分布式系统与安全》这门课，说不定会成为我从本科到硕士期间最有价值的课。"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/SignorMercurio/blog-cdn/DistributedSystems/0.png"><meta property="article:published_time" content="2021-10-18T10:04:07.000Z"><meta property="article:author" content="Mercury"><meta property="article:tag" content="Linux"><meta property="article:tag" content="NFS"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://cdn.jsdelivr.net/gh/SignorMercurio/blog-cdn/DistributedSystems/0.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://signormercurio.me/post/DistributedSystems/"},"headline":"星罗棋布：《分布式系统与安全》课程笔记","image":["https://cdn.jsdelivr.net/gh/SignorMercurio/blog-cdn/DistributedSystems/0.png"],"datePublished":"2021-10-18T10:04:07.000Z","author":{"@type":"Person","name":"Mercury"},"publisher":{"@type":"Organization","name":"Lab on Mercury","logo":{"@type":"ImageObject","url":"https://signormercurio.me/img/favicon.png"}},"description":"《分布式系统与安全》这门课，说不定会成为我从本科到硕士期间最有价值的课。"}</script><link rel="canonical" href="https://signormercurio.me/post/DistributedSystems/"><link rel="alternate" href="/atom.xml" title="Lab on Mercury" type="application/atom+xml"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css"><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><meta name="generator" content="Hexo 5.2.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/favicon.png" alt="Lab on Mercury" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://cdn.jsdelivr.net/gh/SignorMercurio/blog-cdn/DistributedSystems/0.png" alt="星罗棋布：《分布式系统与安全》课程笔记"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-10-18T10:04:07.000Z" title="2021/10/18 上午11:04:07">2021-10-18</time></span><span class="level-item"><a class="link-muted" href="/categories/%E6%8E%A2%E7%B4%A2/">探索</a></span><span class="level-item">an hour read (About 10691 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">星罗棋布：《分布式系统与安全》课程笔记</h1><div class="content"><p>《分布式系统与安全》这门课，说不定会成为我从本科到硕士期间最有价值的课。</p>
<a id="more"></a>

<h2 id="序"><a href="#序" class="headerlink" title="序"></a>序</h2><p>我最初因为选了《恶意软件》这门课，没敢选同一学期同样硬核的《分布式系统与安全》。后来一方面是因为《恶意软件》过于形式化、一方面是因为接触了分布式系统的生态，我选择了换课。第一节课开始没多久，我便确信自己做出了明智的（或许还是影响深远的）决定。</p>
<p>Brad Karp 老师讲解清晰又不失风趣，硬是把线上课上出了线下课的体验。尽管才上了两周的课，我相信这门课会让我受益匪浅。</p>
<blockquote>
<p>一开始给我留下比较好的印象的就是老师摒弃了学校的课程平台 Moodle，转而使用 GitHub Classroom 和 Piazza。众所周知，所谓学校的课程平台并不会给师生带来什么好的体验。</p>
<p>此外，GitHub Classroom 还能自动测试和批改作业，很有意思，使用体验也很好。</p>
</blockquote>
<p>这门课是没有教材的，这实际上对老师的水平提出了很高的要求：他必须自己四处收集资源备课、讲述自己的理解，而非将教材上的内容略作修改、照本宣科。取而代之的阅读材料是一系列经典论文。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="中心化系统面临的问题"><a href="#中心化系统面临的问题" class="headerlink" title="中心化系统面临的问题"></a>中心化系统面临的问题</h3><ul>
<li>单节点故障</li>
<li>难以支撑流量较大的应用</li>
<li>易受攻击，且受到攻击后损失较大（这其实也应该算到单节点故障里？可能不能算故障）</li>
<li>难以伸缩以提高资源利用率</li>
<li>升级与维护时必须中止服务</li>
<li>地理距离带来的网络延迟</li>
</ul>
<h3 id="分布式系统引入的问题"><a href="#分布式系统引入的问题" class="headerlink" title="分布式系统引入的问题"></a>分布式系统引入的问题</h3><ul>
<li>数据一致性</li>
<li>节点间的网络延迟、网络错误</li>
<li>Heterogeneity 异质性，不同节点可能使用不同语言、接口、API 等</li>
<li>节点间并发问题</li>
<li>Partition resilience，不知道怎么翻译，弹性划分问题？</li>
</ul>
<blockquote>
<p>关于 Partition resilience 问题：假设两个用户在两个不同的服务节点上同时购买了最后一张机票，这张机票就会被卖出两次。有点像数据一致性问题。</p>
</blockquote>
<h3 id="OS-相关"><a href="#OS-相关" class="headerlink" title="OS 相关"></a>OS 相关</h3><p>这个部分基本是本科《操作系统》课和 Pwn 的内容，记录时顺便复习下。</p>
<h4 id="Syscall"><a href="#Syscall" class="headerlink" title="Syscall"></a>Syscall</h4><p>例如，应用通过 <code>close(3)</code> 关闭文件。而在 C 函数库中是这样调用 syscall 的：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">close(x) &#123;</span><br><span class="line">  R0 &lt;- <span class="number">73</span></span><br><span class="line">  R1 &lt;- x</span><br><span class="line">  TRAP</span><br><span class="line">  RET</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>TRAP 实际上做的是：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">XP &lt;- PC</span><br><span class="line"><span class="comment">// switch to kernel address space</span></span><br><span class="line"><span class="comment">// set privileged flag (to enter high privlege mode)</span></span><br><span class="line">PC &lt;- address of kernel trap handler</span><br></pre></td></tr></table></figure>

<p>这里的 XP 是某个用来暂时存放 PC 的寄存器。我们容易想到，之后就要在内核中运行代码了，这其实是十分危险的操作。怎么保证应用不会在内核里乱搞呢？答案是 Protected Transfer 机制。</p>
<p>为了避免用户在内核里随便运行代码，只有通过 kernel entrypoint 进入内核才能运行代码，而这个 entrypoint 就是 trap handler。至于具体跳到内核的什么位置则由硬件决定，而不能由应用来指定。这个具体位置则只能通过在启动时运行的内核态代码来决定，确保了用户态程序无法随意跳转到内核任意位置。</p>
<p>接着，在内核的 trap handler 中：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// save regs to this process&#x27; PCB</span></span><br><span class="line">SP &lt;- kernel <span class="built_in">stack</span></span><br><span class="line">sys_close()</span><br><span class="line"><span class="comment">// executing in &quot;kernel half&quot; of process</span></span><br><span class="line"><span class="comment">// restore regs from PCB</span></span><br><span class="line">TRAPRET</span><br></pre></td></tr></table></figure>

<p>最后的 TRAPRET 的流程就比较简单了：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PC &lt;- XP</span><br><span class="line"><span class="comment">// clear privileged flag</span></span><br><span class="line"><span class="comment">// switch to process address space</span></span><br><span class="line"><span class="comment">// continue execution</span></span><br></pre></td></tr></table></figure>

<p>可以看到，TRAP 和 TRAPRET 要保存 / 恢复 PC、切换地址空间、切换用户态 / 内核态，而 trap handler 要保存 / 恢复寄存器，这些过程是必需的但又并没有产生实际的价值，还相对比较耗时。</p>
<h3 id="并发-IO"><a href="#并发-IO" class="headerlink" title="并发 IO"></a>并发 IO</h3><p>而且，Syscall 常常涉及阻塞 IO 操作，很大程度上降低了资源利用率。一般来说有如下三种解决方法：</p>
<ul>
<li>多进程</li>
<li>单进程、多线程</li>
<li>事件驱动 IO</li>
</ul>
<p>但首先，OS 本身对单进程单线程也提供了一定程度的并发 IO，比如：</p>
<ul>
<li>在文件系统中，会进行 read-ahead 和 write-behind 预读写磁盘数据</li>
<li>类似地，<code>read()</code> 接收网络包时也会拷贝到 kernel socket buffer，<code>write()</code> 发送数据包时也会拷贝到 kernel socket buffer</li>
</ul>
<h4 id="多进程"><a href="#多进程" class="headerlink" title="多进程"></a>多进程</h4><p>多进程很容易理解：当一个进程阻塞后，切换到另一个进程运行。优点在于：</p>
<ul>
<li>进程间本身就相互隔离，不会互相影响</li>
<li>（如果有多个 CPU）同时还自动获得了 CPU 并发</li>
</ul>
<p>不过 CPU 并发没有 IO 并发那么重要，相对 IO 并发而言更难实现，两者对速度的提升也是 2 倍和 100 倍的数量级。此时，氪金多买几台机器显然是更好的选择。</p>
<p>然而，多进程也有缺点：</p>
<ul>
<li><code>fork()</code> 调用本身比较耗时、耗内存，300 微秒左右的耗时并不能通过提升机器配置来缩短</li>
<li>隔离性同时也是缺点，不共享内存意味着构建缓存或是记录统计数据比较麻烦</li>
</ul>
<h4 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h4><p>另一种方法是使用更轻量级的线程，此时线程们共享内存且分别拥有自己的栈，维持了一定的独立性。这一好处带来的是非常棘手的问题，那就是线程之间本身会互相影响、线程对数据的读写同样如此，使得我们不得不引入锁的机制来避免这些问题。但是引入新机制又会带来新问题，比如饥饿、死锁等。</p>
<blockquote>
<p>这很像之前看到的火箭工程：要让火箭飞起来就需要带足够的燃料，但这些燃料本身也有重量，于是需要更多的燃料让整个火箭飞起来……<del>（坎巴拉太空计划核心玩法）</del></p>
</blockquote>
<p>几乎所有现代操作系统都对多线程有原生支持，这一般是通过内核线程实现的。这种实现下，内核清楚地知道每个线程的状态，也可以亲自调度线程到 CPU 上，非常灵活且同时支持 CPU 并发和 IO 并发。对于线程来说，每个线程不仅需要原有的用户态栈，还需要维护自己的内核栈和寄存器表。</p>
<p>这么做的代价就是：</p>
<ul>
<li>创建线程要内核干涉</li>
<li>线程上下文切换要内核干涉</li>
<li>加锁解锁也要内核干涉</li>
<li>实现起来很大程度上依赖于 OS，难以移植</li>
</ul>
<p>至于用户线程，对内核来说就是不可见的，内核只负责调度进程。此时，进程内部就需要一个线程调度器，清晰地知道每个线程的状态如何并及时调度。这样我们就可以进行非阻塞式 Syscall 了：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">read() &#123;</span><br><span class="line">  <span class="comment">// tell kernel to start read</span></span><br><span class="line">  <span class="comment">// mark thread waiting for read</span></span><br><span class="line">  sched();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">sched() &#123;</span><br><span class="line">  <span class="comment">// ask kernel for IO completion events</span></span><br><span class="line">  <span class="comment">// mark corresponding threads runnable</span></span><br><span class="line">  <span class="comment">// find runnable thread</span></span><br><span class="line">  <span class="comment">// restore regs and return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>看起来很不错，但是仔细想想，这中间涉及的事件通知机制，需要我们的调度器具备相当强大的能力。它需要让内核通知它：</p>
<ul>
<li>创建网络连接事件</li>
<li>数据到达 socket 事件</li>
<li>磁盘读取完成事件</li>
<li>socket 能够继续被 <code>write()</code> 事件</li>
</ul>
<p>……这基本上就是在组装一个小型 OS 了。更不用说，事件通知机制在 OS 里一般也没有完整的支持，比如在 Unix 中就没有文件系统操作完成事件的通知机制。Syscall 也并不总是能完全不进行阻塞等待，比如 <code>open()</code> 和 <code>stat()</code> 等。</p>
<p>最后，非阻塞式 Syscall 还很难实现。例如可以看下 <code>sys_read()</code> 的大致实现：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sys_read(fd, user_buffer, n) &#123;</span><br><span class="line">  <span class="comment">// read the file&#x27;s i-node from disk</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">inode</span> *<span class="title">i</span> =</span> alloc_inode();</span><br><span class="line">  start_disk(..., i);</span><br><span class="line">  wait_for_disk(i);</span><br><span class="line">  <span class="comment">// the i-node tells us where the data are; read it</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">buf</span> *<span class="title">b</span> =</span> alloc_buf(i-&gt;...);</span><br><span class="line">  start_disk(..., b);</span><br><span class="line">  wait_for_disk(b);</span><br><span class="line">  copy_to_user(b, user_buffer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个函数分为两步，先获取 inode，再写入 buffer，期间都需要 <code>wait_for_disk()</code>，使得程序在内核中被挂起。这种情况下，非阻塞式的 Syscall 此时需要从内核中返回防止阻塞，但这样内核就无从知晓 <code>sys_read()</code> 刚才执行到哪里了，<code>sys_read()</code> 也没法继续执行下去了。</p>
<p>因此，如果要使用用户线程，我们要么只能使用一个支持不那么完整的实现，要么就是重写底层的 Syscall 使得一个 Syscall 内部执行一个非阻塞的过程。这会导致一个 <code>open()</code> 的系统调用可能会被拆成几十个小系统调用，比如通过 <code>lookup_one_path_component()</code> 查找<strong>一层</strong>目录。毫无疑问，这会导致代码极其繁琐。</p>
<p>总的来说，可能只有对性能有苛刻要求的情况下才会使用用户线程，以节省掉用户态 / 内核态切换的开销。</p>
<h2 id="NFS"><a href="#NFS" class="headerlink" title="NFS"></a>NFS</h2><p>这里主要讨论 NFS v2。</p>
<h3 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h3><ul>
<li>应当能够用于现存的应用，即提供与 Unix 文件系统相同的语义</li>
<li>应当能够简单地部署</li>
<li>应当支持多种平台</li>
<li>应当足够高效，但不需要和 Unix 本地文件系统一样高效</li>
</ul>
<h3 id="远程文件与目录的命名"><a href="#远程文件与目录的命名" class="headerlink" title="远程文件与目录的命名"></a>远程文件与目录的命名</h3><p>NFS Client 使用 mounter 将远程目录挂载到本地目录。mounter 向指定的 NFS Server 发送 RPC 请求并获得一个 32 字节的 file handle 用于后续请求，可以将 file handle 理解为 inode。对 NFS Server 而言，file handle 实际上由 fs identifier、inode number 和 generation number 三部分组成。</p>
<p>为什么 NFS 不直接用常规的文件路径来标识文件呢？当然是为了处理数据一致性的问题。假设一个 Client 打开了 <code>dir1</code> 下的文件正准备读取，此时另一个 Client 却重命名了这个目录为 <code>dir2</code>，那么根据 Unix 规范最终读取的路径是 <code>dir2/xxx</code> 。如果 NFS 直接用文件路径标识文件，就无法与 Unix 文件系统的行为保持一致，这也是 file handle 中引入 inode 的原因。</p>
<p>那么 generation number 又有什么用？假设一个 Client 打开了一个文件正准备读区，此时另一个 Client 却删除了这个文件，创建了新的同名文件，那么根据 Unix 规范最终读取的是旧文件的内容。如果 NFS 恰好将旧文件的 inode 分配给新创建的文件，就会导致读到的是新文件的内容。generation number 则会在重用 inode 时 +1，确保读到的是原来的旧文件。解决了重用 inode 的风险，NFS Server 就能立刻回收 inode。</p>
<p>即使 Client 打开文件获得 file handle 后 Server 宕机，这个 file handle 在 Server 恢复后依然有效。</p>
<h3 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h3><p>以读文件为例：</p>
<pre class="mermaid">sequenceDiagram
    participant A as Application
    participant C as Client
    participant S as Server
    A->>C: OPEN("f",0)
    C->>S: LOOKUP(dirfh,"f")
    S->>S: Look up "f" in directory dirfh
    S->>C: fh and file attributes
    C->>A: fd
    A->>C: READ(fd,buf,n)
    C->>S: READ(fh,0,n)
    S->>S: Read from fh
    S->>C: Data and file attributes
    C->>A: Data
    A->>C: CLOSE(fd)</pre>

<p>图中的 <code>fh</code> 指 file handler，并且默认 Application 之前已经获得了目录的 file handler 即 <code>dirfh</code>。</p>
<p>从图中可以看到，Server 并不需要维护任何客户端状态，每次 RPC 请求中带着读文件所需要的全部信息，也就是说 Server 是一个无状态服务。无状态服务的好处在于：</p>
<ul>
<li>对 Server 来说，从故障中恢复并不需要做任何额外的事，就好像故障从来没发生过一样</li>
<li>对 Client 来说，如果请求没有得到响应，只要不断重试即可</li>
</ul>
<p>重试导致的结果是，同一个请求可能被 Server 执行多次，如果是类似删除文件等请求，就会出现奇怪的结果。后来，NFS 通过让 Server 维护一个 transaction ID 和 reply cache 来避免这一问题，不过 reply cache 就会在重启后失效了。换而言之，如果 Client 在 Server 正常时删除了文件，Server 重启后再次删除，依然会得到“文件不存在”的错误，但这种情况已经是小概率事件了。</p>
<p>如果使用一种更健全的方案，就需要持久化到磁盘上这会带来很大的开销和实现复杂度。NFS 选择不这么做，就是为了确保系统的内部实现足够简单，同时保持了无状态的特性。这种为了实现简单而有意牺牲一小部分正确性、一致性和完备性的做法正是 <a target="_blank" rel="noopener" href="https://www.jwz.org/doc/worse-is-better.html">Worse is Better</a> 的设计思想。</p>
<h3 id="扩展-Unix-文件系统"><a href="#扩展-Unix-文件系统" class="headerlink" title="扩展 Unix 文件系统"></a>扩展 Unix 文件系统</h3><p>为了更无缝地适配到 Unix 文件系统，NFS 引入了 vnode 的概念，这实际上是对 inode 的一层抽象，使得 vnode 既可标识本地文件，又可标识远程文件。同时，vnode 还可以标识同一台机器上几种不同文件系统中的文件。</p>
<p>vnode 提供的接口使得开发者无需关心操作的文件来自哪里，许多现有程序代码也更容易迁移。</p>
<p>例如，当应用程序调用 <code>open</code> 系统调用时，会通过 <code>File syscall layer-&gt;Vnode layer-&gt;Client-&gt;Server-&gt;Vnode layer-&gt;File system</code> 的路径一步步 <code>LOOKUP</code> 并最终打开文件。</p>
<p> Client 也会对最近使用的 vnode 进行缓存以减少 RPC 请求。然而，多个 Client 缓存了同一个文件时，就会缓存一致性的问题。</p>
<h3 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h3><p>如果一个应用写了本地文件，文件的改动通常会写入缓存而不是立刻写入 Server。在这段时间里，另一个 Client 读取到的文件就是尚未更新的文件，引起缓存一致性问题。</p>
<p>NFS 提供了两种保证缓存一致性的方法：</p>
<ul>
<li>close-to-open consistency<ul>
<li>如果先 <code>CLOSE </code>后 <code>OPEN</code>，就能保证 <code>READ</code> 读到的数据一定是 <code>WRITE</code> 操作之后的</li>
<li>如果在 <code>CLOSE</code> 前 <code>OPEN</code>，则<strong>无法保证这一点</strong>，这也是缓存一致性和数据一致性的区别所在</li>
</ul>
</li>
<li>read-write consistency：如果 <code>OPEN</code> 了同一文件，则 <code>READ</code> 读到的数据一定是 <code>WRITE</code> 操作之后的，显然这样更能保证一致性但开销更大</li>
</ul>
<p>close-to-open consistency 的具体原理，是每次应用 <code>OPEN</code> 文件时，都会检查本地缓存中文件的修改时间和 <code>GETATTR</code> RPC 请求所获得的 vnode 修改时间，如果不一致，则删除缓存重新获取文件。而 <code>WRITE</code> 则只会写到本地缓存，直到 <code>CLOSE</code> 后改动才会写到 Server 中。</p>
<h3 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h3><ul>
<li>安全性：NFS 并没有把安全性放在一个重要的地位，未授权访问、中间人攻击都是可行的</li>
<li>可伸缩性：NFS Server 承受的流量压力较大，无法支持过多 NFS Client</li>
<li>因为性能、丢包处理等原因，难以在大规模复杂网络中使用</li>
</ul>
<blockquote>
<p>为什么 NFS 安全措施极弱，但却没有受到严重的攻击？主要原因可能是 file handle 难以猜解。</p>
</blockquote>
<h2 id="RPC-透明性"><a href="#RPC-透明性" class="headerlink" title="RPC 透明性"></a>RPC 透明性</h2><h3 id="设计目标-1"><a href="#设计目标-1" class="headerlink" title="设计目标"></a>设计目标</h3><p>编写分布式系统代码时，尽可能减少对客户端和服务端的代码和行为上的改动，并使得开发者无需关心网络带来的问题。也就是说，RPC 希望能让分布式编程写起来就像在单点系统中一样，提供“透明性”。</p>
<h3 id="抽象"><a href="#抽象" class="headerlink" title="抽象"></a>抽象</h3><p>首先面临的问题就是，在不同机器上对数据的表示不同，例如 32 位 / 64 位、小端法 / 大端法等等。因此，在数据传递时，必须使用一种和机器无关的数据表示方式，即 Interface Description Language。</p>
<p>IDL 所做的事不外乎两件：</p>
<ul>
<li>将不同编程语言原生的数据类型，序列化为机器无关的字节流以在网络上传递（反之同理）</li>
<li>在客户端上使用 stub 将请求发送至服务端</li>
</ul>
<p>例如，对于 Sun RPC 来说，IDL 就是 XDR，也是在 CW1 中使用的 IDL。首先在 <code>proto.x</code> 中编写 API 定义，随后 <code>rpcgen proto.x</code> 自动生成代码。</p>
<h3 id="🌰：NFS"><a href="#🌰：NFS" class="headerlink" title="🌰：NFS"></a>🌰：NFS</h3><p>在 NFS 中，Client 本质上就是针对文件 syscall 的一个 RPC stub。此时，syscall 的参数、返回值都没有受到影响，提供了一定程度的透明性。</p>
<p>然而，这种透明性仅仅是形式上的。如果只有形式上的透明性而没有语义上的透明性，现有的代码尽管能够运行，却会产生错误的结果。所谓语义透明性，即同样的调用是否在 NFS 和 Unix 本地文件系统上表现一致。显然，NFS 没能提供这种语义透明性：</p>
<ul>
<li>在 Unix 上，只有文件不存在时 <code>open()</code> 才会失败；在 NFS 上，如果服务器宕机，<code>open()</code> 也会失败，甚至可能一直挂起</li>
<li>在 Unix 上，<code>close()</code> 不可能失败；在 NFS 上，调用 <code>close()</code> 时会触发批量写操作（也就是含有隐性的 <code>write()</code> ），在 Server 空间不足时可能失败</li>
<li>在 NFS 上，假如 Client 发送重命名请求，Server 完成了重命名但未能发送响应就宕机了，那么在 Server 恢复后 Client 的重传会得到“文件不存在”的响应，这在 Unix 上不可能发生</li>
<li>在 Unix 上，如果 A 打开文件后该文件被 B 删除，A 依然能继续读文件；在 NFS 上，A 则无法再读该文件</li>
</ul>
<p>第一个问题并不是 NFS 特有的，而是分布式系统均面临的问题；而后三个问题虽然可以修复以提升语义透明性，但都需要付出性能的代价。同理，提升性能也常常需要牺牲一部分一致性，例如上文提及的 close-to-open consistency，并不是什么时候都能提供足够强的一致性。</p>
<h3 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h3><p>RPC 需要处理类似服务端宕机、网络丢包等单点系统中不存在的异常，并采用 At-most-once 的执行策略。这是因为，如果响应丢包了，客户端会重传已经执行过的请求，此时如果操作具有幂等性则不会出问题，但如果是类似于充值 / 收费等请求，再次执行显然会带来大麻烦。因此，服务端可以维护 replay cache，使得收到重复请求时直接返回 cache 中的值，而不是再执行一次。</p>
<h2 id="Ivy"><a href="#Ivy" class="headerlink" title="Ivy"></a>Ivy</h2><p>RPC 对于提升透明性的尝试基本失败了，它显式的通信方式需要开发者小心地定义节点间的通信接口，没能提升太多透明性。我们转而思考，能不能使用一种隐式的通信方式来达到这一目的呢？分布式共享内存提供了这样一种可能性。</p>
<p>Ivy 创建了一种所有节点共享同一块内存的幻象，隐藏了在访问其他节点内存时底层的网络传输，从而实现隐式的通信。当然，既然用到网络，就要面临网络带来的性能、正确性、一致性等问题……</p>
<p>因为 Ivy 让分布式系统的节点“共享”同一内存，我们不妨将各节点具象为 CPU。首先需要解决的问题就是怎么把程序的不同部分交给不同 CPU 去执行，并确保正确性。</p>
<blockquote>
<p>现代 CPU 并不会按指令顺序来逐条执行指令。所谓正确性，即执行结果看起来就像是指令逐条执行后产生的结果一样。</p>
</blockquote>
<p>如果我们让每个 CPU 都持有一份全部共享内存的复制，那么读内存会非常快。然而，写内存则需要将写操作引入的改变传播到其他 CPU，而网络延迟在这里是不可忽视的。本地读和异地写的时间差，以及节点间网络延迟的差异，都会使得变量值的变化在时间上不一致，从而破坏正确性。因此，这种方案不可行，每个 CPU 必须持有共享内存的一部分而不是全部。</p>
<p>这就引出了如何划分内存给 CPU 的问题。容易想到，固定的划分方法无法顾及局部性，势必会效率低下。而动态的划分方法——比如 CPU 对某个页进行读写时将其移动到 CPU 上——不能处理多个 CPU 读同一个页的情况。</p>
<p>因此，我们可以考虑仅仅在写时移动页。而当 CPU 需要读异地内存时，只需要找到最后写该页的 CPU 并复制一份只读的拷贝。</p>
<h3 id="机制简介-中心化-Manager"><a href="#机制简介-中心化-Manager" class="headerlink" title="机制简介 - 中心化 Manager"></a>机制简介 - 中心化 Manager</h3><p>Ivy 就采用了类似的思想，用中心化的 Manager 管理页的分配，下面用例子阐释其中的机制。假设存在三个 CPU，其中第三个 CPU 同时还是 Manager。每个 CPU 维护自己的 page table，Manager 则额外维护一个 info table。</p>
<table>
<thead>
<tr>
<th>ptable</th>
<th>lock</th>
<th>access</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>CPU0</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>CPU1</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>CPU2</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>info</th>
<th>lock</th>
<th>copy_set</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>Manager</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p><code>lock</code> 列用来锁定表的编辑权限，<code>access</code> 可以为 <code>R</code> / <code>W</code> / <code>nil</code> 表示 CPU 对该页有读 / 读写 / 无权限，<code>owner</code> 则标志当前 CPU 是否为最后写该页的 CPU。最后，info 表中 <code>copy_set</code> 维护了该页的所有只读拷贝，<code>owner</code> 保存了最后写该页的 CPU 名称。</p>
<p>注意这里每个 CPU 的 ptable 和 Manager 的 info table 都被简化到了一行，即对应某一特定的页。</p>
<h4 id="CPU1-读-CPU0-的页"><a href="#CPU1-读-CPU0-的页" class="headerlink" title="CPU1 读 CPU0 的页"></a>CPU1 读 CPU0 的页</h4><p>假设初始状态如下，页为 CPU0 所拥有：</p>
<table>
<thead>
<tr>
<th>ptable</th>
<th>lock</th>
<th>access</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>CPU0</td>
<td>❎</td>
<td>W</td>
<td>✅</td>
</tr>
<tr>
<td>CPU1</td>
<td>❎</td>
<td>nil</td>
<td>❎</td>
</tr>
<tr>
<td>CPU2</td>
<td>❎</td>
<td>nil</td>
<td>❎</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>info</th>
<th>lock</th>
<th>copy_set</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>Manager</td>
<td>❎</td>
<td>{}</td>
<td>CPU0</td>
</tr>
</tbody></table>
<p>现在，CPU1 想要读取该页。于是它首先 lock 了自己 ptable 中对应的行，向 Manager 发送 read query。Manager 接收后，lock 自己 info 中对应的行，将 CPU1 加入 <code>copy_set</code>。</p>
<table>
<thead>
<tr>
<th>ptable</th>
<th>lock</th>
<th>access</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>CPU0</td>
<td>❎</td>
<td>W</td>
<td>✅</td>
</tr>
<tr>
<td>CPU1</td>
<td>✅</td>
<td>nil</td>
<td>❎</td>
</tr>
<tr>
<td>CPU2</td>
<td>❎</td>
<td>nil</td>
<td>❎</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>info</th>
<th>lock</th>
<th>copy_set</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>Manager</td>
<td>✅</td>
<td>{CPU1}</td>
<td>CPU0</td>
</tr>
</tbody></table>
<p>随后，Manager 向 Owner 也就是 CPU0 发送 read forward。CPU0 接收后，lock ptable，将 <code>access</code> 改为 <code>R</code>。</p>
<table>
<thead>
<tr>
<th>ptable</th>
<th>lock</th>
<th>access</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>CPU0</td>
<td>✅</td>
<td>R</td>
<td>✅</td>
</tr>
<tr>
<td>CPU1</td>
<td>✅</td>
<td>nil</td>
<td>❎</td>
</tr>
<tr>
<td>CPU2</td>
<td>❎</td>
<td>nil</td>
<td>❎</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>info</th>
<th>lock</th>
<th>copy_set</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>Manager</td>
<td>✅</td>
<td>{CPU1}</td>
<td>CPU0</td>
</tr>
</tbody></table>
<p>随后，CPU0 向 CPU1 发送 read data 后 unlock ptable。CPU1 接收后，向 Manager 发送 read confirm，并将 <code>access</code> 改为 <code>R</code>，最后 unlock ptable。Manager 收到后，也 unlock info。</p>
<table>
<thead>
<tr>
<th>ptable</th>
<th>lock</th>
<th>access</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>CPU0</td>
<td>❎</td>
<td>R</td>
<td>✅</td>
</tr>
<tr>
<td>CPU1</td>
<td>❎</td>
<td>R</td>
<td>❎</td>
</tr>
<tr>
<td>CPU2</td>
<td>❎</td>
<td>nil</td>
<td>❎</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>info</th>
<th>lock</th>
<th>copy_set</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>Manager</td>
<td>❎</td>
<td>{CPU1}</td>
<td>CPU0</td>
</tr>
</tbody></table>
<h4 id="CPU2-写-CPU0-的页"><a href="#CPU2-写-CPU0-的页" class="headerlink" title="CPU2 写 CPU0 的页"></a>CPU2 写 CPU0 的页</h4><p>书接上回，此时 CPU2 想写 CPU0 的页，那么它会 lock ptable，向 Manager 发送 write query。Manager 接收后，lock info，并向 <code>copy_set</code> 中的 CPU1 发送 invalidate，以撤销 CPU1 的读权限。CPU1 接收后，lock ptable 并将 <code>access</code> 改为 <code>nil</code>。</p>
<table>
<thead>
<tr>
<th>ptable</th>
<th>lock</th>
<th>access</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>CPU0</td>
<td>❎</td>
<td>R</td>
<td>✅</td>
</tr>
<tr>
<td>CPU1</td>
<td>✅</td>
<td>nil</td>
<td>❎</td>
</tr>
<tr>
<td>CPU2</td>
<td>✅</td>
<td>nil</td>
<td>❎</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>info</th>
<th>lock</th>
<th>copy_set</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>Manager</td>
<td>✅</td>
<td>{CPU1}</td>
<td>CPU0</td>
</tr>
</tbody></table>
<p>随后，CPU1 向 Manager 发送 invalidate confirm 并 unlock ptable。Manager 接收后，从 <code>copy_set</code> 中移除 CPU1，向 Owner 即 CPU0 发送 write forward。</p>
<table>
<thead>
<tr>
<th>ptable</th>
<th>lock</th>
<th>access</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>CPU0</td>
<td>❎</td>
<td>R</td>
<td>✅</td>
</tr>
<tr>
<td>CPU1</td>
<td>❎</td>
<td>nil</td>
<td>❎</td>
</tr>
<tr>
<td>CPU2</td>
<td>✅</td>
<td>nil</td>
<td>❎</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>info</th>
<th>lock</th>
<th>copy_set</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>Manager</td>
<td>✅</td>
<td>{}</td>
<td>CPU0</td>
</tr>
</tbody></table>
<p>CPU0 接收后，lock ptable，将 <code>access</code> 设为 <code>nil</code> 并放弃 Owner 身份，最后向 CPU2 发送 write data。</p>
<table>
<thead>
<tr>
<th>ptable</th>
<th>lock</th>
<th>access</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>CPU0</td>
<td>✅</td>
<td>nil</td>
<td>❎</td>
</tr>
<tr>
<td>CPU1</td>
<td>❎</td>
<td>nil</td>
<td>❎</td>
</tr>
<tr>
<td>CPU2</td>
<td>✅</td>
<td>nil</td>
<td>❎</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>info</th>
<th>lock</th>
<th>copy_set</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>Manager</td>
<td>✅</td>
<td>{}</td>
<td>CPU0</td>
</tr>
</tbody></table>
<p>随后，CPU0 unlock ptable。CPU2 接收后，将 <code>access</code> 设为 <code>W</code> 并成为新的 Owner，最后向 Manager 发送 write confirm 并 unlock ptable。</p>
<table>
<thead>
<tr>
<th>ptable</th>
<th>lock</th>
<th>access</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>CPU0</td>
<td>❎</td>
<td>nil</td>
<td>❎</td>
</tr>
<tr>
<td>CPU1</td>
<td>❎</td>
<td>nil</td>
<td>❎</td>
</tr>
<tr>
<td>CPU2</td>
<td>❎</td>
<td>W</td>
<td>✅</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>info</th>
<th>lock</th>
<th>copy_set</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>Manager</td>
<td>✅</td>
<td>{}</td>
<td>CPU0</td>
</tr>
</tbody></table>
<p>Manager 接收后，将 <code>owner</code> 设为 CPU2，最后 unlock info。</p>
<table>
<thead>
<tr>
<th>ptable</th>
<th>lock</th>
<th>access</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>CPU0</td>
<td>❎</td>
<td>nil</td>
<td>❎</td>
</tr>
<tr>
<td>CPU1</td>
<td>❎</td>
<td>nil</td>
<td>❎</td>
</tr>
<tr>
<td>CPU2</td>
<td>❎</td>
<td>W</td>
<td>✅</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>info</th>
<th>lock</th>
<th>copy_set</th>
<th>owner</th>
</tr>
</thead>
<tbody><tr>
<td>Manager</td>
<td>❎</td>
<td>{}</td>
<td>CPU2</td>
</tr>
</tbody></table>
<p>可以注意到，ptable 的锁的存在本质上防止了并发写的发生，使得写操作必须是原子的。</p>
<p>我们也可以将 <code>copy_set</code> 移动至每个 CPU 上而不是放在 Manager 上，使得 confirm 类的消息不需要再被发送。此外，还可以使用分布式 Manager 进一步提升性能。</p>
<h3 id="与-RPC-对比"><a href="#与-RPC-对比" class="headerlink" title="与 RPC 对比"></a>与 RPC 对比</h3><p>相比 RPC，分布式共享内存的优点在于：</p>
<ul>
<li>提供了更强的透明性</li>
<li>使得分布式系统编程更为容易</li>
</ul>
<p>然而，RPC 同样具备分布式共享内存欠缺的优点：</p>
<ul>
<li>更好的隔离性</li>
<li>对通信更可控</li>
<li>对网络延迟容忍度更高</li>
<li>更容易移植到不同平台</li>
</ul>
<h2 id="2PC"><a href="#2PC" class="headerlink" title="2PC"></a>2PC</h2><p>NFS 和 Ivy 都没有处理系统中节点故障的问题。在一些场景下（比如银行转帐），我们希望当参与的节点故障时，所有参与的节点要么都完成状态变更，要么都没有状态变更。比如，我们显然不希望发起转账的节点被扣除了余额，而收到转账的节点没有增加余额。</p>
<p>2PC（Two-Phase Commit）即两阶段提交，通过一种非常简单的思路来确保系统中的节点能达成<strong>共识</strong>。如果这种 all-or-nothing 的语义能够被正确执行，即要么全 commit 要么全 abort，那么就达成了 Safety 的目标；如果在没有故障的情况下能尽快全 commit，并在出现故障的情况下尽快决定是 commit 还是 abort，那么就达成了 Liveness 目标。显然，Safety 和 Liveness 两者之间需要权衡。</p>
<p>为此，我们需要引入交易协调者 TC。假设系统中只有两个节点 A 和 B，那么 TC 先向两者发送 prepare 消息。A 和 B 随后回复他们是否能够 commit。如果 TC 收到了两个 Yes，那么就会向两者发送 commit 消息；如果 TC 收到了至少一个 No，那么就会向两者发送 abort 消息。最后，A 和 B 根据 TC 的指令完成相应动作。</p>
<p>我们可以很容易看出，上述做法一定能保证 Safety。但是，如果：</p>
<ul>
<li>任意节点（TC / A / B）接收消息时超时了（宕机、丢包种种原因）</li>
<li>任意节点重启了</li>
</ul>
<p>我们都无法保证 Liveness 了，因为 TC 可能在能够 commit 的情况下选择了 abort。</p>
<h3 id="超时的情况"><a href="#超时的情况" class="headerlink" title="超时的情况"></a>超时的情况</h3><p>为了处理超时的情况，确保 Safety 的前提下尽量保证 Liveness：</p>
<ol>
<li><p>我们可以让 TC 等待 Yes / No 消息超时的时候选择 abort 来尽快作出决定，但此时依然有可能在能 commit 的情况下选择了 abort，过于保守。</p>
</li>
<li><p>我们可以让 A / B 等待 commit / abort 消息超时的时候自动选择 commit，但由于另一方可能回复了 No，这样很可能失去 Safety。</p>
</li>
<li><p>我们可以让 A / B 等待 commit / abort 消息超时的时候自动选择 abort。不失一般性，假如 B 之前回复了 No，那么超时自动 abort 不会出问题，也能保证 Liveness；但如果 B 之前回复了 Yes，那么 TC 就有可能收到两个 Yes，然后给 A 发送 commit，而给 B 发送的 commit 没有送达。此时 A 选择 commit 而 B 自动 abort 了，失去了 Safety！</p>
</li>
</ol>
<p>至此，我们解决了问题的一半：B 如果之前回复了 No，那么只要超时自动 abort 就好了。</p>
<p>而如果 B 之前回复了 Yes，那么它可以向 A 发送 status 消息，询问 A 的状态：</p>
<ul>
<li>如果 A 没有回复，B 无法决定，只能继续永远等 TC 的消息；</li>
<li>如果 A 收到了 commit / abort 并回复给了 B ，B 就做相同的决定；</li>
<li>如果 A 还没有回复 Yes / No，两者都 abort（此时 TC 不可能决定全 commit）；</li>
<li>如果 A 没收到 commit / abort 但之前回复了 No，两者都 abort；</li>
<li>如果 A 没收到 commit / abort 但之前回复了 Yes，B 同样无法决定，因为无法判断 TC 是不是收到了两者的 Yes 并决定 commit 了。</li>
</ul>
<p>因此，我们发现即使采用了这样的终止协议并保证了 Safety，Liveness 依然无法保证，TC 宕机 / TC 的消息丢了的情况下，A / B 依然需要永远等待 TC。</p>
<h3 id="重启的情况"><a href="#重启的情况" class="headerlink" title="重启的情况"></a>重启的情况</h3><p>重启的 TC 可能不知道自己发送过 commit，重启的 A / B 可能不知道自己发送过 Yes，结合丢包的可能性，这使得作出能保证 Safety 的决定也不那么容易了。</p>
<p>对于这类问题，分布式系统采用的一种通用方案就是借助持久化存储。TC 发送 commit 前先写一条记录到磁盘，A / B 在发送 Yes 前也先写一条记录到磁盘，就能使状态被保留下来。</p>
<p>因此，只需要：</p>
<ul>
<li>TC 重启后，如果磁盘上没有 commit 消息，就 abort；</li>
<li>A / B 重启后，如果磁盘上没有 Yes 消息，就 abort；</li>
<li>A / B 重启后，如果磁盘上有 Yes 消息，就使用上述的终止协议作决定</li>
</ul>
<h3 id="FLP-Result"><a href="#FLP-Result" class="headerlink" title="FLP Result"></a>FLP Result</h3><p>分析了 2PC 协议之后，我们发现尽管它能保证 Safety，但却不能在所有情况下保证 Liveness。实际上，根据 <a target="_blank" rel="noopener" href="https://www.the-paper-trail.org/post/2008-08-13-a-brief-tour-of-flp-impossibility/">FLP Result</a>，异步消息传递式的分布式系统中，只要有一台机器存在宕机且不恢复的可能（crash-failure），就不存在确定性的共识算法，也就是说不可能同时保证 Safety 和 Liveness。</p>
<h2 id="Paxos"><a href="#Paxos" class="headerlink" title="Paxos"></a>Paxos</h2><p>称 Paxos 为分布式领域最重要的算法应该不会有太大争议。Paxos 实际上可以认为是 2PC 的升级版，因为两者都是为了解决<strong>共识</strong>问题，只不过 Paxos 通过更复杂的机制获得了更高的可用性。在之前介绍的案例中（NFS、Ivy、2PC）其实都没有将可用性纳入考量。</p>
<p>需要注意的是 Paxos 是共识算法而不是一致性算法，尽管这两个概念很相似。共识指的是系统中的节点对某个 / 某些变量的值、或者是某个概念、某个行动能够达成共识，而一致性则指的是不同的分布式数据库节点上，存储的数据是否一致。</p>
<p>假如有这样一个场景：我们要选择一个节点作为 primary，负责接收客户端请求并分发给其他 backup 节点。但是 primary 的引入同时也会引入单点故障问题，此时可能就需要选出一个新的 primary，这时就会极易产生多于一个 primary。在这个场景下，Paxos 要解决的问题就是：确保所有节点最终只会选出一个 primary。而对于其他不同场景，Paxos 解决的问题也可以不同。</p>
<p>一个很自然的想法是给每个节点预先编号，当前存活的节点中编号最小的当选。这就需要所有节点对“当前存活的节点集合”这个值达成共识。然而未必所有节点都能够正常地给出自己的反馈，因此只需要某个值被<strong>超过半数</strong>节点同意，我们就认为节点关于这个值达成了共识。</p>
<blockquote>
<p> 这实际上表明，Paxos 能成功执行必须要至少半数以上的节点存活。</p>
</blockquote>
<p>由于可能出现网络丢包和网络分区，单纯的互 ping 来确定哪些节点存活是行不通的。为此，Paxos 引入了 Leader 机制。当一个节点决定成为 Leader 后，它会向包括自身在内的所有节点广播一个 proposal，其中包含一个 proposal 序号 n 和相应的值 value（在这个例子里，是存活节点集合，下不赘述）。n 必须是全局唯一的，一般取目前存在的最大的 n 的值 + 1。</p>
<p>我们用 <code>n_a</code>表示节点之前已经 accept 过的 proposal 中最大的 n，然后用 <code>v_a</code> 表示对应 proposal 的 value。再用 <code>n_h</code> 记录节点所收到的 proposal 中最大的 n。当节点收到一个 proposal，并发现其序号 n 大于 <code>n_h</code> 时，就将 <code>n_h</code> 设为 n，并向 Leader 回复 <code>(n_a, v_a)</code>。</p>
<p>Leader 收到了超过半数的这样的消息后，就可以查看其中是否有某个 <code>v_a</code> 非空。如果所有 <code>v_a</code> 都是空的，那么就自己选择一个值作为 value；否则，就选择 <code>n_a</code> 最大的那个消息中的 <code>v_a</code> 作为 value。随后，向这次回复过自己的节点广播 <code>(n = 最大的 n_a, v = 选择的 value)</code>。</p>
<p>节点收到后，如果发现 <code>n</code> 大于等于 <code>n_h</code>，那就接收这个 proposal。所谓接收 proposal，就是设置 <code>n_h = n_a = n</code>，<code>v_a = v</code> 来更新这几条记录，随后回复一条没有内容的消息。</p>
<p>Leader 收到超过半数的这样的消息后，就可以认为节点达成了共识，并向这次回复过自己的节点广播一条没有内容的消息，表示共识已达成。节点收到消息后，就知道最终达成的共识的值为 <code>v_a</code>。在选 primary 的例子里，<code>v_a</code> 集合里序号最小的节点就是公认的 primary 了。</p>
<p>那么，一个节点怎么决定自己要成为 Leader 呢？很简单，只要为每个节点设置一个随机的超时时间，一旦过了这个时间依然没有来自 Leader 的消息，节点就会自己成为 Leader。</p>
<p>Paxos 能保证 Safety 的关键在于：</p>
<ul>
<li>任何节点收到一个 <code>n &lt; n_h</code> 的消息后，都会直接无视，这使得即使出现多个 Leader，节点最终也只会 accept 那个序号最大的 proposal（注意 n 是全局唯一的）</li>
<li>任意两个“超过半数”的集合之间必定存在交集，这是由“超过半数”的定义得来的。这使得即使出现多个 Leader，并且都几乎获得了超过半数的支持，最终也会由这个交集中的节点（哪怕只有一个）决定要 accept 的 proposal</li>
<li>新的 proposal 会沿用现存的 <code>n_a</code> 最大的 proposal 对应的 value，这使得不同 Leader 发起的处于不同阶段的 proposal，无法影响到最终达成共识的 value</li>
</ul>
<h2 id="Bayou"><a href="#Bayou" class="headerlink" title="Bayou"></a>Bayou</h2><p>Bayou 是为了移动设备构建成的分布式系统设计的，而移动设备经常会遇到没有网络或者网络质量差的情况，这使得很多问题，比如数据一致性，看起来非常困难甚至不可解。Bayou 解决这些问题的手段主要是通过节点间通信，比如通过蓝牙之类的协议使得两部手机交换数据来达成一致性。这是因为 Bayou 主要想解决的问题就是严重网络分区情况下的数据读写可用性。</p>
<p>Bayou 使用了一个会议室预订系统来说明协议的运作原理和场景。最终，系统需要确保同一时间段同一会议室不会被两个用户预订。为此，需要一种自动解决冲突的机制，使得不同节点上的数据同步之后能像 git 那样 merge 掉冲突。为了实现这个机制，需要节点维护一个更新操作的有序列表，并确保节点收到的更新操作是一致的、以及确保节点会按相同的顺序逐个应用这些更新操作。这样一来，数据同步就只需要像归并排序那样，合并两个有序列表即可。</p>
<p>不过 Bayou 并不是仅仅用于会议室预订系统，而是一个通用的协议，因此需要考虑的问题是：什么才算冲突？这个问题的答案对于不同应用是不同的。同理，合并操作也是类似的。举个例子，对于会议室预订系统，假如我们想预订从下午一点半开始持续一小时的会议，我们会在写操作里添加这样的依赖检查和合并算法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">query &#x3D; &quot;SELECT key FROM Meetings WHERE day&#x3D;12&#x2F;18&#x2F;95 AND start &lt; 2:30pm AND end &gt; 1:30pm&quot;</span><br><span class="line">expected_result &#x3D; EMPTY</span><br><span class="line">merge_proc &#x3D; ......</span><br></pre></td></tr></table></figure>

<p>随后，Bayou 就会检查 <code>query</code> 的结果是否等于 <code>expected_result</code> ，是的话可以直接更新，否则就需要调用 <code>mergeproc</code> 来合并冲突。需要注意的是，依赖检查和合并算法需要是确定性的。这样一来，由于每个服务器都会按照相同顺序解决冲突，每个服务器最终获得的结果也是相同的。</p>
<p>当一个写操作被接收时，它首先处于 tentative 状态，并且会根据其 timestamp 被排序；最终，写操作会变成 commited 状态，同样根据其被 commit 时的 timestamp 进行排序，并且必定排在 tentative 写操作的前面。这里 Bayou 使用了 Lamport Clock 来避免解决不同设备上的时钟同步问题。</p>
<p>一个让人不爽但又无可奈何的事情是，当 Bayou 服务器接收到新的写操作时，之前的写操作可能不得不被撤销，然后根据新的顺序重新执行。因为新的写操作的加入，旧的写操作甚至可能出现和之前不同的执行结果。当一个写操作最后一次被执行完毕，我们就称该操作已经是稳定的了。对于预订会议室的用户来说，了解自己的预订是否已经稳定显然十分重要。</p>
<p>那么，Bayou 服务器如何确定一个写操作是否已经稳定了呢？一种办法是用 Lamport Clock 里的 timestamp，如果一个写操作的 timestamp 已经小于任何服务器收到的新的写操作的 timstamp，那说明在这个写操作之前已经没有其他写操作了，所以一定是稳定的。但是，如果一个服务器长期断线，那么它上线的时候就会导致大量写操作重新执行。</p>
<p>Bayou 采用的方法是 primary commit 方法。因为 commited 排在 tentative 前面，我们可以说一个写操作被 commit 之后，只要节点已经获得了之前所有 commited 的写操作（必然成立，这是由 Bayou 按顺序传播写操作的机制决定的），那么这次就是已经是稳定的了。primary commit 即选择一个服务器作为 primary，由它来执行 commit 的操作，并将数据同步给其他服务器。这样做的好处有：</p>
<ul>
<li>即使 primary 出现单点故障，影响的也只是 commit，而不是正常的读写操作。</li>
<li>即使某些节点长期断线，也不影响 commit，因为只有 primary 能 commit。</li>
<li>节点接收到来自 primary 的数据同步后，就不再需要最新 commit 之前的任何记录了，因为那些记录都不可能再改变了。</li>
</ul>
<p>最后，必须注意的是，primary 在决定 commit 顺序的时候，对于来自同一节点的若干次写操作，其顺序必须被保留。如果在某个节点上先执行了 create，然后执行 modify，那么让 modify 在 create 前面 commit 是毫无意义的。</p>
<p>可以看到，Bayou 的问题主要在于实现依赖检查和合并算法，很大程度上增加了开发 / 使用一个应用的复杂度，也并不是对所有应用都适合用这种办法。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>星罗棋布：《分布式系统与安全》课程笔记</p><p><a href="https://signormercurio.me/post/DistributedSystems/">https://signormercurio.me/post/DistributedSystems/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Mercury</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2021-10-18</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="" rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Linux/">Linux</a><a class="link-muted mr-2" rel="tag" href="/tags/NFS/">NFS</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/post/Kubernetes/"><span class="level-item">乘风破浪：Kubernetes 笔记</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div class="content" id="valine-thread"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script><script>new Valine({
            el: '#valine-thread',
            appId: "RkxCznUcvfzFBgfMiMr0BAfd-gzGzoHsz",
            appKey: "sw2sEPOl4haCAXKUFYiBFMrR",
            placeholder: "Leave comments here...",
            avatar: "mm",
            avatarForce: false,
            meta: ["nick","mail","link"],
            pageSize: 10,
            lang: "en",
            visitor: true,
            highlight: true,
            recordIP: false,
            
            
            
            enableQQ: false,
            requiredFields: ["nick","mail"],
        });</script></div></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#序"><span class="level-left"><span class="level-item">1</span><span class="level-item">序</span></span></a></li><li><a class="level is-mobile" href="#背景"><span class="level-left"><span class="level-item">2</span><span class="level-item">背景</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#中心化系统面临的问题"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">中心化系统面临的问题</span></span></a></li><li><a class="level is-mobile" href="#分布式系统引入的问题"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">分布式系统引入的问题</span></span></a></li><li><a class="level is-mobile" href="#OS-相关"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">OS 相关</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Syscall"><span class="level-left"><span class="level-item">2.3.1</span><span class="level-item">Syscall</span></span></a></li></ul></li><li><a class="level is-mobile" href="#并发-IO"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">并发 IO</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#多进程"><span class="level-left"><span class="level-item">2.4.1</span><span class="level-item">多进程</span></span></a></li><li><a class="level is-mobile" href="#多线程"><span class="level-left"><span class="level-item">2.4.2</span><span class="level-item">多线程</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#NFS"><span class="level-left"><span class="level-item">3</span><span class="level-item">NFS</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#设计目标"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">设计目标</span></span></a></li><li><a class="level is-mobile" href="#远程文件与目录的命名"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">远程文件与目录的命名</span></span></a></li><li><a class="level is-mobile" href="#RPC"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">RPC</span></span></a></li><li><a class="level is-mobile" href="#扩展-Unix-文件系统"><span class="level-left"><span class="level-item">3.4</span><span class="level-item">扩展 Unix 文件系统</span></span></a></li><li><a class="level is-mobile" href="#缓存一致性"><span class="level-left"><span class="level-item">3.5</span><span class="level-item">缓存一致性</span></span></a></li><li><a class="level is-mobile" href="#局限性"><span class="level-left"><span class="level-item">3.6</span><span class="level-item">局限性</span></span></a></li></ul></li><li><a class="level is-mobile" href="#RPC-透明性"><span class="level-left"><span class="level-item">4</span><span class="level-item">RPC 透明性</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#设计目标-1"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">设计目标</span></span></a></li><li><a class="level is-mobile" href="#抽象"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">抽象</span></span></a></li><li><a class="level is-mobile" href="#🌰：NFS"><span class="level-left"><span class="level-item">4.3</span><span class="level-item">🌰：NFS</span></span></a></li><li><a class="level is-mobile" href="#异常处理"><span class="level-left"><span class="level-item">4.4</span><span class="level-item">异常处理</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Ivy"><span class="level-left"><span class="level-item">5</span><span class="level-item">Ivy</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#机制简介-中心化-Manager"><span class="level-left"><span class="level-item">5.1</span><span class="level-item">机制简介 - 中心化 Manager</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#CPU1-读-CPU0-的页"><span class="level-left"><span class="level-item">5.1.1</span><span class="level-item">CPU1 读 CPU0 的页</span></span></a></li><li><a class="level is-mobile" href="#CPU2-写-CPU0-的页"><span class="level-left"><span class="level-item">5.1.2</span><span class="level-item">CPU2 写 CPU0 的页</span></span></a></li></ul></li><li><a class="level is-mobile" href="#与-RPC-对比"><span class="level-left"><span class="level-item">5.2</span><span class="level-item">与 RPC 对比</span></span></a></li></ul></li><li><a class="level is-mobile" href="#2PC"><span class="level-left"><span class="level-item">6</span><span class="level-item">2PC</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#超时的情况"><span class="level-left"><span class="level-item">6.1</span><span class="level-item">超时的情况</span></span></a></li><li><a class="level is-mobile" href="#重启的情况"><span class="level-left"><span class="level-item">6.2</span><span class="level-item">重启的情况</span></span></a></li><li><a class="level is-mobile" href="#FLP-Result"><span class="level-left"><span class="level-item">6.3</span><span class="level-item">FLP Result</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Paxos"><span class="level-left"><span class="level-item">7</span><span class="level-item">Paxos</span></span></a></li><li><a class="level is-mobile" href="#Bayou"><span class="level-left"><span class="level-item">8</span><span class="level-item">Bayou</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-10-18T10:04:07.000Z">2021-10-18</time></p><p class="title"><a href="/post/DistributedSystems/">星罗棋布：《分布式系统与安全》课程笔记</a></p><p class="categories"><a href="/categories/%E6%8E%A2%E7%B4%A2/">探索</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-10-10T15:31:41.000Z">2021-10-10</time></p><p class="title"><a href="/post/Kubernetes/">乘风破浪：Kubernetes 笔记</a></p><p class="categories"><a href="/categories/%E4%BA%91/">云</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-09-25T17:44:35.000Z">2021-09-25</time></p><p class="title"><a href="/post/Dockerfile2GKE/">再探 GitHub Actions：从 Dockerfile 到 GKE</a></p><p class="categories"><a href="/categories/%E4%BA%91/">云</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-09-23T09:03:42.000Z">2021-09-23</time></p><p class="title"><a href="/post/GCP/">高枕无忧：Google Cloud Platform 基础</a></p><p class="categories"><a href="/categories/%E4%BA%91/">云</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-09-10T08:27:59.000Z">2021-09-10</time></p><p class="title"><a href="/post/CloudNative/">风谲云诡：云原生技术原理</a></p><p class="categories"><a href="/categories/%E4%BA%91/">云</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/favicon.png" alt="Lab on Mercury" height="28"></a><p class="is-size-7"><span>&copy; 2021 Mercury</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><script src="/js/main.js" defer></script><script src="https://unpkg.com/mermaid@8.13.3/dist/mermaid.min.js"></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>